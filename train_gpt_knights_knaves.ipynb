{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GPT on Knights and Knaves Puzzles\n",
    "\n",
    "This notebook trains a GPT model on 100M Knights and Knaves puzzles.\n",
    "Designed for 8xB200 GPUs but can be adapted for other configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Add the current directory to the path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('__file__')))\n",
    "\n",
    "from data.knights_knaves import get\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.utils import set_seed, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We'll start with a smaller subset for testing, then scale up to the full 100M dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Knights and Knaves dataset\n",
    "# For initial testing, use max_games=100000 (100k puzzles)\n",
    "# For full training, set max_games=None to use all 100M puzzles\n",
    "\n",
    "knights_knaves = get(\n",
    "    data_path=\"data/n_2.jsonl\",\n",
    "    max_games=100000,  # Start with 100k for testing\n",
    "    val_split=0.1,     # 10% validation for small dataset, use 0.01 for full dataset\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character dataset wrapper\n",
    "train_dataset = CharDataset(knights_knaves)\n",
    "print(f\"Vocabulary size: {train_dataset.vocab_size}\")\n",
    "print(f\"Block size: {train_dataset.block_size}\")\n",
    "print(f\"Number of training sequences: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a sample puzzle\n",
    "sample_idx = 0\n",
    "sample_puzzle = knights_knaves.train[sample_idx]\n",
    "print(\"Sample puzzle (as characters):\")\n",
    "print(''.join([c for c in sample_puzzle if c != -100]))\n",
    "print(\"\\nTokenized:\")\n",
    "print([train_dataset.stoi.get(c, 0) for c in sample_puzzle[:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "# For 100M dataset on 8xB200 GPUs, we can use a larger model\n",
    "mconf = GPTConfig(\n",
    "    vocab_size=train_dataset.vocab_size,\n",
    "    block_size=train_dataset.block_size,\n",
    "    n_layer=12,      # 12 layers for larger dataset\n",
    "    n_head=12,       # 12 attention heads\n",
    "    n_embd=768,      # 768 embedding dimensions\n",
    "    embd_pdrop=0.1,\n",
    "    resid_pdrop=0.1,\n",
    "    attn_pdrop=0.1,\n",
    ")\n",
    "\n",
    "model = GPT(mconf)\n",
    "\n",
    "# Print model size\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1024**3:.2f} GB (assuming float32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "# For 8xB200 GPUs\n",
    "batch_size_per_gpu = 1024\n",
    "num_gpus = torch.cuda.device_count()\n",
    "total_batch_size = batch_size_per_gpu * num_gpus\n",
    "\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "print(f\"Batch size per GPU: {batch_size_per_gpu}\")\n",
    "print(f\"Total batch size: {total_batch_size}\")\n",
    "\n",
    "# For single GPU testing, use smaller batch size\n",
    "if num_gpus == 1:\n",
    "    total_batch_size = 64\n",
    "    print(f\"Using single GPU with batch size: {total_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "max_epochs = 10\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs,\n",
    "    batch_size=total_batch_size,\n",
    "    learning_rate=6e-4,\n",
    "    lr_decay=True,\n",
    "    warmup_tokens=len(train_dataset) * train_dataset.block_size * 0.1,  # 10% warmup\n",
    "    final_tokens=len(train_dataset) * train_dataset.block_size * max_epochs,\n",
    "    num_workers=4,\n",
    "    ckpt_path=f\"./ckpts/gpt_knights_knaves{t_start}.ckpt\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "print(f\"Training on device: {device}\")\n",
    "print(f\"Checkpoint will be saved to: {tconf.ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model from checkpoint\n",
    "# checkpoint_path = \"./ckpts/gpt_knights_knaves_YYYYMMDD_HHMMSS.ckpt\"\n",
    "# model.load_state_dict(torch.load(checkpoint_path))\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Test the model's ability to solve Knights and Knaves puzzles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(model, puzzle_text, device, temperature=0.1):\n",
    "    \"\"\"Generate a solution for a Knights and Knaves puzzle.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Add the separator\n",
    "    context = puzzle_text + \" => \"\n",
    "    \n",
    "    # Encode the context\n",
    "    x = torch.tensor([train_dataset.stoi.get(s, 0) for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "    \n",
    "    # Generate prediction (expecting 2-3 characters for solution like \"KN\" or \"NNK\")\n",
    "    with torch.no_grad():\n",
    "        y = sample(model, x, 10, temperature=temperature)[0]\n",
    "    \n",
    "    # Decode the prediction\n",
    "    completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "    \n",
    "    # Extract just the solution part (K/N characters)\n",
    "    solution = ''.join([c for c in completion if c in ['K', 'N']])\n",
    "    \n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on a sample of puzzles\n",
    "model.eval()\n",
    "num_test = min(100, len(knights_knaves.val))\n",
    "correct = 0\n",
    "\n",
    "for i in tqdm(range(num_test), desc=\"Validating\"):\n",
    "    # Get validation puzzle\n",
    "    puzzle_chars = knights_knaves.val[i]\n",
    "    puzzle_text = ''.join([c for c in puzzle_chars if c != -100])\n",
    "    \n",
    "    # Split puzzle and solution\n",
    "    if \" => \" in puzzle_text:\n",
    "        puzzle_part, actual_solution = puzzle_text.split(\" => \")\n",
    "        \n",
    "        # Generate prediction\n",
    "        predicted_solution = generate_solution(model, puzzle_part, device)\n",
    "        \n",
    "        # Compare\n",
    "        if predicted_solution == actual_solution:\n",
    "            correct += 1\n",
    "        \n",
    "        # Show first few examples\n",
    "        if i < 5:\n",
    "            print(f\"\\nPuzzle {i}:\")\n",
    "            print(f\"Input: {puzzle_part[:100]}...\" if len(puzzle_part) > 100 else f\"Input: {puzzle_part}\")\n",
    "            print(f\"Actual: {actual_solution}\")\n",
    "            print(f\"Predicted: {predicted_solution}\")\n",
    "            print(f\"Correct: {predicted_solution == actual_solution}\")\n",
    "\n",
    "accuracy = correct / num_test\n",
    "print(f\"\\nValidation accuracy: {correct}/{num_test} = {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a custom puzzle\n",
    "test_puzzle = \"says 0 (isKnight 1), says 1 (isKnave 0)\"\n",
    "solution = generate_solution(model, test_puzzle, device, temperature=0.1)\n",
    "print(f\"Puzzle: {test_puzzle}\")\n",
    "print(f\"Predicted solution: {solution}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "for i, s in enumerate(solution):\n",
    "    print(f\"Agent {i}: {'Knight' if s == 'K' else 'Knave'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final trained model\n",
    "final_checkpoint_path = f\"./ckpts/gpt_knights_knaves_final{t_start}.ckpt\"\n",
    "torch.save(model.state_dict(), final_checkpoint_path)\n",
    "print(f\"Model saved to: {final_checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
